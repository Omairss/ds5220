%
% DS 5220 Final
%
\documentclass[12pt]{article}

%
% Packages
%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{clrscode3e}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage[table]{xcolor}% http://ctan.org/pkg/xcolor
\usepackage{caption}
\usepackage{subcaption}


%
% Package settings
%

%% begin.rcode setup, include=FALSE
% library(knitr)
%
% opts_chunk$set(fig.path='figure/latex-', cache.path='cache/latex-')
%% end.rcode

%
% Document Settings
%
\setlength{\parskip}{1pc}
\setlength{\parindent}{0pt}
\setlength{\topmargin}{-3pc}
\setlength{\textheight}{9.5in}
\setlength{\oddsidemargin}{0pc}
\setlength{\evensidemargin}{0pc}
\setlength{\textwidth}{6.5in}


\title{Quick, Draw! Image Classification}
\author{Group 3}

%
% Image directory location
%
\graphicspath{ {./imgs/} }

\begin{document}

\maketitle

\section{Introduction}

Many recent industry innovations have included neural networks. An
important research area within neural networks has been image classification.
One of the best techniques to classify images is Convolutional Neural
Networks (CNN). We have sought to better understand industry best practices
by exploring different image classification techniques with neural networks.
Our exploration starts by manually performing image classification and
noting the level of human accuracy. We then use a fully connected neural
network to perform image classification before implementing a CNN. We
implemented options for tuning and debugging the neural network while
implementing each method during our process. We were able to develop an
intuition for image classification best practices using neural networks
after our research.

Many supervised machine learning methods often differ from those employed 
when constructing neural networks. These supervised machine learning
methods, such as logistic regression or decision tree classification,
require feature engineering to successfully classify an image. Models
requiring feature engineering rely on considerable effort by subject matter
experts to achieve reasonable accuracy. Neural networks allow for an
approach which does not require feature engineering to achieve similar or
better accuracy. Industry engineering efforts regarding feature engineering
can be shifted to neural networks  in some cases such as image
classification. Moreover, the availability of cheap computing resources
sped up a shift towards the use of neural networks.

When considering modeling approaches, we examine both fully connected and 
convolutional neural networks. A fully connected neural network is known to 
be inefficient at classifying large images. These inefficiencies in a fully 
connected neural network partly arise because every neuron in the $\ell-1$
layer must be connected to the $\ell$th layer. This requires a series
of matrix multiplications and additions across each layer $\ell$.
Alternatively, a CNN allows for more efficient computations by: (1) efficient
and automatic feature generation using local connectivity and parameter
sharing of convolution operations, (2) dimensionality reduction using pooling
layers. In this project, we attempt to understand these topics in depth
from an empirical stanpoint in relation to image classification using
Google's ``Quick, Draw!'' dataset.

\section{Methods}

Our methodology consists of reviewing statistical methodology, presenting
theoretically informed hypotheses, and providing an overview of our data.

\subsection{Overview of Statistical Modeling Techniques}

We use human classification, fully connected neural networks,
and a Convolutional Neural Network (CNN). We use more detail to
describe techniques not covered during the course.

\subsubsection{Understanding the Loss Function}

Most modern neural networks are trained using maximum likelihood. This
means that the cost function is the negative log-likelihood, also
described as the cross-entropy between the training data and the model
distribution \cite{Goodfellow-et-al-2016}. In our use case, we are interested
in correctly classifying 10 categories of drawings. Our output unit
use a Softmax function in our output layer because they are most often
used for classifiers representing the probability distribution over
$n$ different classes. Given features $h$, weights $W$, and bias $b$, a
linear layer first predicts unnormalized log probabilities:
\begin{equation}
  z = W^Th + b 
\end{equation}

where $z_i = \log \tilde{P}(y = i | x)$. The softmax function can then
exponentiate and normalize $z$ to obtain the desired $\hat{y}$. The
softmax function is given by
\begin{equation}
  \func{softmax}(z)_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)}.
\end{equation}

As a cost function, we wish to maximize
$\log P(y=i; z) = \log \func{softmax}(z)_i$. We can do this formally as
\begin{equation}
  \log \func{softmax}(z)_i = z_i - \log \sum_j \exp(z_j).
\end{equation}

which gives us the intuition for a single example. Overall, we want to learn
parameters that drive the softmax to predict the fraction of counts of each
outcome observed in the training set \cite{Goodfellow-et-al-2016}:
\begin{equation}
  \func{softmax}(z(x;\theta))_i \approx \frac{\sum_{j=1}^m 1_{y^{(j)} = i,
      x^{(j)} = x}}{\sum_{j=1}^m 1_{x^{(j)} = x}}.
\end{equation}

This is how the $\func{categorical\_crossetropy}(\text{y\_true}, \text{y\_pred})$ function is constructed in Keras \cite{chollet2015keras} as well as the
$\func{softmax\_cross\_entropy\_with\_logits\_v2}(\text{labels}, \text{logits})$ in Tensorflow \cite{tensorflow2015-whitepaper}. 

\subsubsection{Understanding the Optimization Technique}

This course discussed optimization algorithms such as Stochastic Gradient
Descent ($m =1$) and Batch Gradient Descent ($m=n \text{ obs.}$). Current
best practices for Neural Networks recommend Mini-Batch Gradient Descent
($m = c \text{ batch size}$). In practice, we use the Adam optimization
algorithm due to faster computation time. The Adam optimization algorithm
is able to achieve a speedup due to its combination of two other techniques.

The Adam optimization algorithm takes an exponentially weighted average of
the gradients, a technique called momentum, and then uses that gradient to
update your weights. Secondly, we also want to slow down gradient descent in
the horizontal direction with a technique called RMSprop to reduce
oscillations from batch gradient descent. The Adam optimization method is
combining momentum and RMSprop to perform gradient descent more quickly
\cite{DeepLear51:online}.

\subsubsection{Convolutional Neural Network (CNN)}

Convolutional networks, also known as convolutional neural networks(CNNs),
are a specialized kind of neural network for processing data that has a
known grid-like topology. Convolutional networks have been tremendously
successful in practical applications. The name “convolutional neural network”
indicates that the network employs a mathematical operation called
convolution. Convolution is a specialized kind of linear operation.
Convolutional networks are simply neural networks that use convolution
in place of general matrix multiplication in at least one of their layers. See
Figure \ref{fig:CNN} in the Appendix for a visual representation of a CNN.

CNN architectures are usually composed of the building blocks as described
below:

\begin{enumerate}
\item \textbf{Convolution:} Convolution operation helps to extract features
  from the input image. The ﬁrst argument to the convolution is often referred
  to as the input , the second argument as the feature detector (kernel) and
  the output as the feature map. The convolution operation takes the dot
  product of feature map and the input to detect features. Since each
  convolution operation only focuses on a part of an image enabling parameter
  sharing which helps to reduce the number of free parameters compared to a
  fully connected neural network, allowing the network to be deeper with
  fewer parameters.

  \begin{itemize}
  \item \textbf{Strides:} Stride is the number of pixels jumps between
    each convolution operation performed on the input matrix. When the stride
    is 1 then we move the filters to 1 pixel at a time. Increasing the stride
    parameter reduces the output volume of the convolution since the jumps
    are larger.
  \item \textbf{Padding:}Padding helps to detect features present at the
    border by adding a dummy values around the edge. Since convolution
    operations collect most information from the center of the image, adding
    padding allows the border pixels to be weighed more during the convolution
    operation.
  \end{itemize}

  See Figure \ref{fig:CNNStridePad} in the Appendix for an example of Stride
  and Padding.

\item \textbf{Pooling Layer:} Pooling layers section helps to reduce the
  number of parameters when the images are too large. Spatial pooling
  (subsampling or downsampling) reduces the dimensionality of each map,
  retaining important information. These can be of different types:
  (1) Max Pooling - takes the largest element (most important feature)
  from the rectified feature map (2) Average Pooling - averages all the
  pixel values (3) Sum Pooling. sum of all pixels values. See figure
  \ref{fig:CNNPooling} for a visualization of a Pooling Layer.

\item \textbf{Fully Connected Layer:} The layer we call as FC layer, we
  flattened our matrix into vector and feed it into a fully connected layer
  like neural network.
  \end{enumerate}

\subsection{Hypotheses}

We have generated the following hypotheses based on theoretical
expectations expressed in the literature \cite{Goodfellow-et-al-2016,
  DeepLear51:online}. Performance is effected by both the model and
data \cite{DeepLear51:online} so our hypotheses pertain to both effects.

\subsubsection{Addressing model component of performance}

\begin{itemize}
  \item[$H1_a$] Fully Connected Neural Network will struggle to get reasonable
    accuracy.
  \item[$H2_a$] CNN should perform better than fully connected neural network.
  \end{itemize}

\subsubsection{Addressing data component of performance}

\begin{itemize}
\item[$H3_a$] Small amounts of data will lead to overfitting.
\item[$H4_a$] Imbalanced class prediction can be improved using data
  augmentation.
\item[$H5_a$] Addition of a category to the trained model will reduce the
  performance of the model.
\item[$H6_a$] Adding more training data will improve the performance of the
  model.
\end{itemize}

\subsection{Data}

Google originally collected the data from users by explicitly asking users to
draw objects like forks, hotdogs, etc \cite{QuickDra91:online}. The original
dataset is 70 GB in size but Google also provides a simplified version of the
dataset- consisting only of the final images \cite{googlecr61:online}. We
used these '.npy' files to train all of our models. These numpy bitmap files
consist of more than 100,000 rows each and 784
features, since they are basically $28 \times 28$ images. Samples of these
images are shown in Figure \ref{fig:quickImages}. The subset of this
dataset sampled varies from experiment to experiment. More details can be
found in the experiments mentioned below.

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{fig1}
  \end{center}
  \caption{Sample images from Quick, Draw! dataset}
  \label{fig:quickImages}
\end{figure}

Our analysis required us to use a subset of this data. Our dataset sample
selected for this experiment had 10 categories: fish, fork, hotdog, flamingo,
airplane, alarm clock, baseball bat, bicycle, dolphin, elephant. We had
100,000 examples in total, with 10,000 example for each of the aforementioned
categories.


\subsection{Modeling Strategy}

We provide our modeling strategy as it relates to the exploration of
our stated hypotheses.

\subsubsection{Baseline image classification using humans}

Two group members completed a Human Intelligence Task by manually
classifying images into one of our ten defined categories. This
approach helped us get a benchmark which we could use to
define ``reasonable accuracy''. 

\subsubsection{$H1_a$: Fully connected neural network will struggle
  to get reasonable accuracy}

In order to perform this experiment, we built a fully connected neural network
using Tensorflow. Our train:test split was chosen to be 80:20, an industry
standard. Our initial objective was to build a model that overfit our given
dataset, with the idea that once our model is complex enough to overfit the
training data, we could regularize it in order to achieve a more optimal fit.
The fully connected neural network had 20,067 parameters.

After experimenting with various architectures, we narrowed down to a 3 layer
model as specified in Figure \ref{fig:fcnn} in the Appendix. The model was
run on a machine with 13 GB of RAM, Intel Xeon CPU 2.3 GHz (1 core, 2
threads), 1xTesla K80 GPU having 2496 CUDA cores with 12 GB GDDR5 VRAM.

\subsubsection{$H2_a$ CNN should perform better than fully connected neural
  network}

As for the CNN, we started off with the same approach with attempting
to overfit the model using convolution operations and a fully connected
layer with an objective to categorise 10 categories, softmax was chosen
as the activation function for the final layer, while every other neuron
had ReLU as the activation function owing to ReLU’s faster convergence. See
Figure \ref{fig:cnnArch} for a representation of this first CNN model.

The number of parameters is much greater than the number of observations
used to train the model resulting in overfitting. In order to reduce the
number of parameters, we incorporated Pooling (Max Pooling) post each
convolution operation extracting only the most significant features
resulting in reduction of the volume of the convolutional output, giving
the model a smaller memory footprint as well as a smaller number of
trainable parameters. Figure \ref{fig:cnnArchPool} has a representation of this
second CNN model. We employ strategies to reduce overfitting related to
dropouts and stride in addition to adding more training data.

\section{Results}

We report our results by examining the validity of each hypothesis.

\subsection{Addressing model component of performance}

In order to perform this experiment we built a fully connected neural network
using tensorflow. Our train:test split was chosen to be 80:20, an industry
standard. 

Our initial objective was to build a model that overfit our given dataset,
with the idea that once our model is complex enough to overfit the training
data, we could regularize it in order to achieve a more optimal fit.

After experimenting with various architectures, we narrowed down to a 3 layer
model as specified in Figure \ref{fig:fcnn}.


The training set accuracy observed was 93\%, while the test accuracy was at
73\%, which clearly indicated an overfit in the model, as designed.

The model took 1500 epochs to converge taking around ~45 minutes on a
machine with 13 GB of RAM, Intel Xeon CPU 2.3 GHz (1 core, 2 threads),
1xTesla K80 GPU having 2496 CUDA cores with 12 GB GDDR5 VRAM. In order to
manage variance, we attempted regularizing using dropouts. Unfortunately,
that effort was futile. We then doubled the amount of data sampled to train
the model, eventually helping us achieve training set accuracy of 86\% and
test set accuracy of 82\%. Our learning rate was specified as 0.001.

While our initial hypothesis assumed that a regular fully connected network
would struggle to achieve a reasonable accuracy, our experiment proved our
hypothesis as invalid by achieving a commendable accuracy. Having said that,
the model did take a longer to converge than expected.

As for the CNN, we started off with the same approach with attempting to
overfit the model using convolution operations and a fully connected layer.
Since our objective is to categorise 10 categories, softmax was chosen as the
activation function for the final layer, while every other neuron had ReLU as
the activation function owing to ReLU’s faster convergence.




Number of Trainable Parameters: 320,890


The number of clearly being much greater than the number of observations used
to train the model, we need to reduce the number of parameters vis-a-vis
number of observations. From the available strategies to do so, we
incorporated MaxPooling [TODO: why?] post each convolution operation, in
order to extract only the most significant features. As as a consequence,
this reduced the volume of the output, giving the model a smaller memory
footprint as well as a smaller number of trainable parameters.


The observable training accuracy is 0.90, whereas the validation accuracy is
0.89. The model converged after 10 epochs, which took ~ 3 minutes.

Some of the other unsuccessful strategies used to decrease the number of
parameters and to regularize the network were strides and dropouts which
sacrificed way too much in the way of accuracy and thus had to be dropped.
Since most of our drawings had most of their information in the center of the
image, padding, in theory wouldn’t be of much help. However, actually
implementing padding improved our accuracy by 1\% at a cost of ~6000
parameters.

Conclusion

A slight (~5\%) improvement in the accuracy of a CNN when compared to a fully connected network, keeping the number of parameters constant, was observed. However, the CNN happened to be around 13 times faster in practice. This delta in accuracy and speed is likely to be amplified as we scale the model up with respect to model complexity or data.

\subsection{Addressing data component of performance}

ok

\section{Discussion}

Talk about our final slide and tie the hypotheses together

\bibliographystyle{unsrt}
\bibliography{references}

\section{Appendix}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.75]{fig2}
    \end{center}
  \caption{Fully Connected Neural Network Architecture}
  \label{fig:fcnn}
\end{figure}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.5]{fig3}
    \end{center}
  \caption{(CNN Model 1) Loss Function: Categorical Cross Entropy, Optimizer:
    Adam, Trainable Parameters: 320,890}
  \label{fig:cnnArch}
\end{figure}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.5]{fig4}
  \end{center}
  \caption{(CNN Model 2) Loss Function: Categorical Cross Entropy, Optimizer:
    Adam, Trainable Parameters: 19,322}
  \label{fig:cnnArchPool}
\end{figure}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.5]{fig5}
    \end{center}
  \caption{CNN Architecture Example}
  \label{fig:CNN}
\end{figure}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.5]{fig6}
    \end{center}
  \caption{Convolution operation with stride=1, padding=None}
  \label{fig:CNNStridePad}
\end{figure}

\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.5]{fig7}
  \end{center}
  \caption{Example of Max Pooling}
  \label{fig:CNNPooling}
  \end{figure}

\end{document}
