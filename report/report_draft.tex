\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Identifying Drawings with the Quick Draw Challenge},
            pdfauthor={Group 3},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Identifying Drawings with the Quick Draw Challenge}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Group 3}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \date{}
  \predate{}\postdate{}


\begin{document}
\maketitle

We're trying to put together a CNN based on the ``Quick, Draw!'' Kaggle
competition (Google 2018).

\section{Introduction}\label{introduction}

Our team has based our project idea on the ``Quick, Draw!'' Kaggle
competition which classifies user drawings into one of 345 label
categories. Many drawings were incomplete or failed to match the label.
The challenge was to effectively build a recognizer that could work with
this noisy data. The challenge was unique from an algorithmic
perspective because the data included both temporal and spatial
components; areas that have traditionally used two different types of
Neural Network Architectures. Our team attempted to provide a solution
using a subset of the data, to the Kaggle problem, while taking a more
in depth look at potential pitfalls and modeling strategy, without
having to use extensive computational resources.

\section{Methods}\label{methods}

First, we got our data from Google/Kaggle. CNNs are traditionally known
to work well with spatial data, which prompted us to process the
original csv files to images of the drawings.

Maybe we should structure our models as experiments. Then talk about
what worked the best. Here's some example hypotheses

\(H_a:\) Prediction will go up when we use a CNN compared to a fully
connected feedforward neural network.

\(H_a:\) Prediction will go up when we use regularization.

\(H_a:\) Run neural networks without any activations.

\(H_a:\) Try different architectures- number of layers, different (or
no) activations

\(H_a:\) CNN with dilation is preferable to LSTM because it's presumably
faster. We can cite some papers here.

Try out: Overfitting, Bias/variance, imbalance, dropout, pushing
activation

\section{Results}\label{results}

Here's how the results performed when we were exploring our hypotheses

\section{Discussion}\label{discussion}

Here's what worked the best, worst, and future areas for research.

\section{References}\label{references}

\section{Appendix}\label{appendix}

Add computer code, plots, and other relevant technical details that will
help me evaluating your work.

\section*{Statement of contribution}\label{statement-of-contribution}
\addcontentsline{toc}{section}{Statement of contribution}

\hypertarget{refs}{}
\hypertarget{ref-QuickDra10}{}
Google. 2018. ``Quick, Draw! Doodle Recognition Challenge \textbar{}
Kaggle.'' \url{https://www.kaggle.com/c/quickdraw-doodle-recognition}.


\end{document}
