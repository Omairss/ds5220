{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_connected_softmax_dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbonza/ds5220/blob/master/full_connected_softmax_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lIoRCAZqWIz6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Constructing a fully connected neural network with a softmax activation function in the output layer. This is meant as a comparison for \"Quick, Draw!\" models using CNN, etc."
      ]
    },
    {
      "metadata": {
        "id": "2RpbySAGWheL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n",
        "Try to keep all the dependencies in one place."
      ]
    },
    {
      "metadata": {
        "id": "7q3Tei1fV-pp",
        "colab_type": "code",
        "outputId": "1271e781-fb0f-4898-ed16-84e50304900f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cloudpickle\n",
        "!pip install dask"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPecH0yEWa-b",
        "colab_type": "code",
        "outputId": "5fc8fee0-a686-4685-aeb4-a7a89a82081a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import base64\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from dask import bag\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "08WU22CGW7Nw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data \n",
        "\n",
        "Loading the data from the [QuickDraw](https://www.kaggle.com/c/quickdraw-doodle-recognition) contest. We also need to convert it, resize it, then put it in a matrix."
      ]
    },
    {
      "metadata": {
        "id": "VtyPNdb1W2i5",
        "colab_type": "code",
        "outputId": "46245b33-0749-4ba5-a17c-20acbdd7b495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrmI0eWhW8ES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_TRAIN = \"gdrive/My Drive/gcolab/X_train.hdf5\"\n",
        "Y_TRAIN = \"gdrive/My Drive/gcolab/y_train.hdf5\"\n",
        "PNG_FOLDER = \"gdrive/My Drive/gcolab/png/\"\n",
        "NPY_FOLDER = \"gdrive/My Drive/gcolab/npy/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Na780wNrXHmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(category, label, sample_size=None):\n",
        "    x = np.load(NPY_FOLDER + category + \".npy\")\n",
        "    y = np.array([label] * x.shape[0])\n",
        "      \n",
        "    ## Trimming the category to sample size\n",
        "    if(sample_size != None):\n",
        "        x = x[:sample_size,:]\n",
        "        y = y[:sample_size]\n",
        "    print(\"Category: {}, Label: {}, X-Shape: {} & Y-Shape: {}\".\\\n",
        "          format(category, label, x.shape, y.shape))\n",
        "    return (x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zN7ZJ9aBXKHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_samples(input_array, rows=1, cols=5, title=''):\n",
        "    fig, ax = plt.subplots(figsize=(cols,rows))\n",
        "    ax.axis('off')\n",
        "    plt.title(title)\n",
        "\n",
        "    for i in list(range(0, min(len(input_array),(rows*cols)) )):      \n",
        "        a = fig.add_subplot(rows,cols,i+1)\n",
        "        imgplot = plt.imshow(input_array[i,:784].reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIA0-rOIXMmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resahape_data(x, y):\n",
        "    x = x.reshape(x.shape[0], 28, 28, 1).astype('float32')\n",
        "    # one hot encode outputs\n",
        "    y = np_utils.to_categorical(y)\n",
        "    print(\"After reshape, x: {}, y:{}\".format(x.shape, y.shape))\n",
        "    return(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCZZ7roaXPSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
        "# Use a 50:50 split, training the models on 10'000 samples and thus have plenty of samples to spare for testing.\n",
        "def get_train_test(x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x/255., y, test_size=0.2, random_state=0)\n",
        "    return(x_train, x_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOH-ei5hXStH",
        "colab_type": "code",
        "outputId": "c74b51ad-a8da-4d56-99bc-e988197edb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "categories = [\"fish\", \"fork\", \"hotdog\", \"flamingo\", \"airplane\", \"alarmclock\", \n",
        "              \"baseballbat\", \"bicycle\", \"dolphin\", \"elephant\"]\n",
        "#categories = [\"airplane\", \"hotdog\"]\n",
        "x = None\n",
        "y = None\n",
        "for i in range(len(categories)):\n",
        "    if(i == 0):\n",
        "        x_temp, y_temp = load_data(categories[i], i, 30000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = x_temp\n",
        "        y = y_temp\n",
        "    else:\n",
        "        x_temp, y_temp = load_data(categories[i], i, 30000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = np.concatenate((x, x_temp), axis=0).astype('float32')\n",
        "        y = np.concatenate((y, y_temp), axis=0).astype('float32')\n",
        "print(\"Shape, x: {}, y:{}\".format(x.shape, y.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category: fish, Label: 0, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: fork, Label: 1, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: hotdog, Label: 2, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: flamingo, Label: 3, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: airplane, Label: 4, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: alarmclock, Label: 5, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: baseballbat, Label: 6, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: bicycle, Label: 7, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: dolphin, Label: 8, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Category: elephant, Label: 9, X-Shape: (30000, 784) & Y-Shape: (30000,)\n",
            "Shape, x: (300000, 784), y:(300000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvWeDv5GXkDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Constructing the Fully Connected Neural Network with Softmax\n",
        "\n",
        "Use Tensorflow to train a fully connected neural network. "
      ]
    },
    {
      "metadata": {
        "id": "u0mqYDWKXfbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uIdCbSIJXq0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xr50IsSUXtWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [10000, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgmM_G23Xv6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
        "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \n",
        "    Tips:\n",
        "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
        "      In fact, the number of examples during test/train is different.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (approx. 2 lines)\n",
        "    X = tf.placeholder(tf.float32, name = 'X', shape=(n_x,None))\n",
        "    Y = tf.placeholder(tf.float32, name = 'Y', shape=(n_y,None))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxMAxyJ1XyeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [25, 12288]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [6, 12]\n",
        "                        b3 : [6, 1]\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
        "        \n",
        "    ### START CODE HERE ### (approx. 6 lines of code)\n",
        "    W1 = tf.get_variable(\"W1\", [25,784], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\", [12,25], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b2 = tf.get_variable(\"b2\", [12, 1], initializer= tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\", [10,12], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b3 = tf.get_variable(\"b3\", [10, 1], initializer=tf.zeros_initializer())\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exlg7bX3X1ig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1,X), b1)                        # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1), b2)                      # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2), b3)                      # Z3 = np.dot(W3,Z2) + b3\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQokFdW5X4UL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(Z3, Y, lambd):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    # Include dropout\n",
        "    logits = tf.nn.dropout(logits, lambd)\n",
        "    \n",
        "    # compute cost\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVgtgnxSX7WL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          lambd = 0.001, num_epochs = 1500, minibatch_size = 100, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
        "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep consistent results\n",
        "    seed = 3                                          # to keep consistent results\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(Z3, Y, lambd)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], \n",
        "                                              feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1PReJQlYKLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running the Model\n",
        "\n",
        "We want to run the fully connected neural network."
      ]
    },
    {
      "metadata": {
        "id": "f0w4wX7sXVt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x, y = resahape_data(x, y)\n",
        "X_train, X_test, y_train, y_test = get_train_test(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ja67u4ZBYApX",
        "colab_type": "code",
        "outputId": "22b52933-4d57-4c9e-e728-fa848ac79870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 240000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "hbUgBssWYOBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "depth = len(categories)\n",
        "sess = tf.Session()\n",
        "y_train = sess.run(tf.one_hot(y_train, depth))\n",
        "y_test = sess.run(tf.one_hot(y_test, depth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6D1dbfRTLoDl",
        "colab_type": "code",
        "outputId": "698cf188-63d7-4ac5-e2f1-2ce10a9b4b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 240000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "01cG-lTXYQWP",
        "colab_type": "code",
        "outputId": "5bf98115-6274-4b4b-a323-c3433db052f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(X_train, y_train, X_test, y_test, learning_rate=0.001,  \n",
        "                   lambd=0.7, num_epochs =1600, minibatch_size=64)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.246490\n",
            "Cost after epoch 100: 0.868654\n",
            "Cost after epoch 200: 0.851079\n",
            "Cost after epoch 300: 0.848116\n",
            "Cost after epoch 400: 0.844714\n",
            "Cost after epoch 500: 0.841455\n",
            "Cost after epoch 600: 0.835619\n",
            "Cost after epoch 700: 0.838067\n",
            "Cost after epoch 800: 0.833314\n",
            "Cost after epoch 900: 0.833386\n",
            "Cost after epoch 1000: 0.832288\n",
            "Cost after epoch 1100: 0.829092\n",
            "Cost after epoch 1200: 0.831770\n",
            "Cost after epoch 1300: 0.830719\n",
            "Cost after epoch 1400: 0.831860\n",
            "Cost after epoch 1500: 0.831278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFhERMZn/B1pODlzQX3kFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7013166e80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.85882914\n",
            "Test Accuracy: 0.81976664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "elxWXwZ1YUJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}