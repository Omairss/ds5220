{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_connected_softmax_dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbonza/ds5220/blob/master/full_connected_softmax_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lIoRCAZqWIz6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Constructing a fully connected neural network with a softmax activation function in the output layer. This is meant as a comparison for \"Quick, Draw!\" models using CNN, etc."
      ]
    },
    {
      "metadata": {
        "id": "2RpbySAGWheL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n",
        "Try to keep all the dependencies in one place."
      ]
    },
    {
      "metadata": {
        "id": "7q3Tei1fV-pp",
        "colab_type": "code",
        "outputId": "b9c3f40f-b658-49d5-99cd-59c24ffe78cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cloudpickle\n",
        "!pip install dask"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPecH0yEWa-b",
        "colab_type": "code",
        "outputId": "cc078536-7df4-4f7e-c62e-acd1b053739f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import base64\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from dask import bag\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "08WU22CGW7Nw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data \n",
        "\n",
        "Loading the data from the [QuickDraw](https://www.kaggle.com/c/quickdraw-doodle-recognition) contest. We also need to convert it, resize it, then put it in a matrix."
      ]
    },
    {
      "metadata": {
        "id": "VtyPNdb1W2i5",
        "colab_type": "code",
        "outputId": "3e0b8646-47c8-4c79-f53f-8760f83e3d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrmI0eWhW8ES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_TRAIN = \"gdrive/My Drive/gcolab/X_train.hdf5\"\n",
        "Y_TRAIN = \"gdrive/My Drive/gcolab/y_train.hdf5\"\n",
        "PNG_FOLDER = \"gdrive/My Drive/gcolab/png/\"\n",
        "NPY_FOLDER = \"gdrive/My Drive/gcolab/npy/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Na780wNrXHmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(category, label, sample_size=None):\n",
        "    x = np.load(NPY_FOLDER + category + \".npy\")\n",
        "    y = np.array([label] * x.shape[0])\n",
        "      \n",
        "    ## Trimming the category to sample size\n",
        "    if(sample_size != None):\n",
        "        x = x[:sample_size,:]\n",
        "        y = y[:sample_size]\n",
        "    print(\"Category: {}, Label: {}, X-Shape: {} & Y-Shape: {}\".\\\n",
        "          format(category, label, x.shape, y.shape))\n",
        "    return (x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zN7ZJ9aBXKHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_samples(input_array, rows=1, cols=5, title=''):\n",
        "    fig, ax = plt.subplots(figsize=(cols,rows))\n",
        "    ax.axis('off')\n",
        "    plt.title(title)\n",
        "\n",
        "    for i in list(range(0, min(len(input_array),(rows*cols)) )):      \n",
        "        a = fig.add_subplot(rows,cols,i+1)\n",
        "        imgplot = plt.imshow(input_array[i,:784].reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIA0-rOIXMmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resahape_data(x, y):\n",
        "    x = x.reshape(x.shape[0], 28, 28, 1).astype('float32')\n",
        "    # one hot encode outputs\n",
        "    y = np_utils.to_categorical(y)\n",
        "    print(\"After reshape, x: {}, y:{}\".format(x.shape, y.shape))\n",
        "    return(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCZZ7roaXPSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
        "# Use a 50:50 split, training the models on 10'000 samples and thus have plenty of samples to spare for testing.\n",
        "def get_train_test(x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x/255., y, test_size=0.2, random_state=0)\n",
        "    return(x_train, x_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOH-ei5hXStH",
        "colab_type": "code",
        "outputId": "a8aeead2-6ca1-46fb-8896-867380f24ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "categories = [\"fish\", \"fork\", \"hotdog\", \"flamingo\", \"airplane\", \"alarmclock\", \n",
        "              \"baseballbat\", \"bicycle\", \"dolphin\", \"elephant\"]\n",
        "#categories = [\"airplane\", \"hotdog\"]\n",
        "x = None\n",
        "y = None\n",
        "for i in range(len(categories)):\n",
        "    if(i == 0):\n",
        "        x_temp, y_temp = load_data(categories[i], i, 20000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = x_temp\n",
        "        y = y_temp\n",
        "    else:\n",
        "        x_temp, y_temp = load_data(categories[i], i, 20000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = np.concatenate((x, x_temp), axis=0).astype('float32')\n",
        "        y = np.concatenate((y, y_temp), axis=0).astype('float32')\n",
        "print(\"Shape, x: {}, y:{}\".format(x.shape, y.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category: fish, Label: 0, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: fork, Label: 1, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: hotdog, Label: 2, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: flamingo, Label: 3, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: airplane, Label: 4, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: alarmclock, Label: 5, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: baseballbat, Label: 6, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: bicycle, Label: 7, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: dolphin, Label: 8, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: elephant, Label: 9, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Shape, x: (200000, 784), y:(200000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvWeDv5GXkDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Constructing the Fully Connected Neural Network with Softmax\n",
        "\n",
        "Use Tensorflow to train a fully connected neural network. "
      ]
    },
    {
      "metadata": {
        "id": "u0mqYDWKXfbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uIdCbSIJXq0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xr50IsSUXtWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [10000, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgmM_G23Xv6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
        "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \n",
        "    Tips:\n",
        "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
        "      In fact, the number of examples during test/train is different.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (approx. 2 lines)\n",
        "    X = tf.placeholder(tf.float32, name = 'X', shape=(n_x,None))\n",
        "    Y = tf.placeholder(tf.float32, name = 'Y', shape=(n_y,None))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxMAxyJ1XyeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [25, 12288]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [6, 12]\n",
        "                        b3 : [6, 1]\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
        "        \n",
        "    ### START CODE HERE ### (approx. 6 lines of code)\n",
        "    W1 = tf.get_variable(\"W1\", [25,784], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\", [12,25], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b2 = tf.get_variable(\"b2\", [12, 1], initializer= tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\", [10,12], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b3 = tf.get_variable(\"b3\", [10, 1], initializer=tf.zeros_initializer())\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exlg7bX3X1ig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1,X), b1)                        # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1), b2)                      # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2), b3)                      # Z3 = np.dot(W3,Z2) + b3\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQokFdW5X4UL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(Z3, Y, lambd):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    # Include dropout\n",
        "    logits = tf.nn.dropout(logits, lambd)\n",
        "    \n",
        "    # compute cost\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVgtgnxSX7WL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          lambd = 0.001, num_epochs = 1500, minibatch_size = 100, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
        "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep consistent results\n",
        "    seed = 3                                          # to keep consistent results\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(Z3, Y, lambd)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], \n",
        "                                              feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1PReJQlYKLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running the Model\n",
        "\n",
        "We want to run the fully connected neural network."
      ]
    },
    {
      "metadata": {
        "id": "f0w4wX7sXVt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x, y = resahape_data(x, y)\n",
        "X_train, X_test, y_train, y_test = get_train_test(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ja67u4ZBYApX",
        "colab_type": "code",
        "outputId": "4add4a9a-7b8a-40c5-adaf-8eb6fd9e6469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "hbUgBssWYOBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "depth = len(categories)\n",
        "sess = tf.Session()\n",
        "y_train = sess.run(tf.one_hot(y_train, depth))\n",
        "y_test = sess.run(tf.one_hot(y_test, depth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6D1dbfRTLoDl",
        "colab_type": "code",
        "outputId": "647b08be-46e1-434c-a3c9-f0a65fa3170b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 100000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "01cG-lTXYQWP",
        "colab_type": "code",
        "outputId": "305e919b-74b8-4bf0-dc11-cde4785f035d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(X_train, y_train, X_test, y_test, learning_rate=0.001,  \n",
        "                   lambd=0.7, num_epochs =1600, minibatch_size=64)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.375224\n",
            "Cost after epoch 100: 0.868620\n",
            "Cost after epoch 200: 0.838703\n",
            "Cost after epoch 300: 0.824353\n",
            "Cost after epoch 400: 0.818657\n",
            "Cost after epoch 500: 0.815188\n",
            "Cost after epoch 600: 0.808385\n",
            "Cost after epoch 700: 0.801546\n",
            "Cost after epoch 800: 0.799282\n",
            "Cost after epoch 900: 0.794118\n",
            "Cost after epoch 1000: 0.794685\n",
            "Cost after epoch 1100: 0.790670\n",
            "Cost after epoch 1200: 0.788910\n",
            "Cost after epoch 1300: 0.786905\n",
            "Cost after epoch 1400: 0.786805\n",
            "Cost after epoch 1500: 0.786403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3aaa6d2ac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.87288\n",
            "Test Accuracy: 0.78976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "elxWXwZ1YUJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}