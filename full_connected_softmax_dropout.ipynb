{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_connected_softmax_dropout.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbonza/ds5220/blob/master/full_connected_softmax_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lIoRCAZqWIz6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Constructing a fully connected neural network with a softmax activation function in the output layer. This is meant as a comparison for \"Quick, Draw!\" models using CNN, etc."
      ]
    },
    {
      "metadata": {
        "id": "2RpbySAGWheL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n",
        "Try to keep all the dependencies in one place."
      ]
    },
    {
      "metadata": {
        "id": "7q3Tei1fV-pp",
        "colab_type": "code",
        "outputId": "db9c8846-ec5b-413c-de8c-8cde04a37164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cloudpickle\n",
        "!pip install dask"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nPecH0yEWa-b",
        "colab_type": "code",
        "outputId": "ae005bd6-d29f-4773-b85b-bf6ec52e2a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import base64\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from dask import bag\n",
        "from google.colab import drive\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "08WU22CGW7Nw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data \n",
        "\n",
        "Loading the data from the [QuickDraw](https://www.kaggle.com/c/quickdraw-doodle-recognition) contest. We also need to convert it, resize it, then put it in a matrix."
      ]
    },
    {
      "metadata": {
        "id": "VtyPNdb1W2i5",
        "colab_type": "code",
        "outputId": "5fd5005a-9612-4e33-a7c9-41ae902f555b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrmI0eWhW8ES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_TRAIN = \"gdrive/My Drive/gcolab/X_train.hdf5\"\n",
        "Y_TRAIN = \"gdrive/My Drive/gcolab/y_train.hdf5\"\n",
        "PNG_FOLDER = \"gdrive/My Drive/gcolab/png/\"\n",
        "NPY_FOLDER = \"gdrive/My Drive/gcolab/npy/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Na780wNrXHmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(category, label, sample_size=None):\n",
        "    x = np.load(NPY_FOLDER + category + \".npy\")\n",
        "    y = np.array([label] * x.shape[0])\n",
        "      \n",
        "    ## Trimming the category to sample size\n",
        "    if(sample_size != None):\n",
        "        x = x[:sample_size,:]\n",
        "        y = y[:sample_size]\n",
        "    print(\"Category: {}, Label: {}, X-Shape: {} & Y-Shape: {}\".\\\n",
        "          format(category, label, x.shape, y.shape))\n",
        "    return (x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zN7ZJ9aBXKHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_samples(input_array, rows=1, cols=5, title=''):\n",
        "    fig, ax = plt.subplots(figsize=(cols,rows))\n",
        "    ax.axis('off')\n",
        "    plt.title(title)\n",
        "\n",
        "    for i in list(range(0, min(len(input_array),(rows*cols)) )):      \n",
        "        a = fig.add_subplot(rows,cols,i+1)\n",
        "        imgplot = plt.imshow(input_array[i,:784].reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIA0-rOIXMmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resahape_data(x, y):\n",
        "    x = x.reshape(x.shape[0], 28, 28, 1).astype('float32')\n",
        "    # one hot encode outputs\n",
        "    y = np_utils.to_categorical(y)\n",
        "    print(\"After reshape, x: {}, y:{}\".format(x.shape, y.shape))\n",
        "    return(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCZZ7roaXPSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
        "# Use a 50:50 split, training the models on 10'000 samples and thus have plenty of samples to spare for testing.\n",
        "def get_train_test(x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x/255., y, test_size=0.2, random_state=0)\n",
        "    return(x_train, x_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOH-ei5hXStH",
        "colab_type": "code",
        "outputId": "7728b296-69b4-41b4-a2c5-62e4782b2c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "categories = [\"fish\", \"fork\", \"hotdog\", \"flamingo\", \"airplane\", \"alarmclock\", \n",
        "              \"baseballbat\", \"bicycle\", \"dolphin\", \"elephant\"]\n",
        "#categories = [\"airplane\", \"hotdog\"]\n",
        "x = None\n",
        "y = None\n",
        "for i in range(len(categories)):\n",
        "    if(i == 0):\n",
        "        x_temp, y_temp = load_data(categories[i], i, 20000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = x_temp\n",
        "        y = y_temp\n",
        "    else:\n",
        "        x_temp, y_temp = load_data(categories[i], i, 20000)\n",
        "        #plot_samples(x_temp, rows=1, cols=5, title=categories[i])\n",
        "        x = np.concatenate((x, x_temp), axis=0).astype('float32')\n",
        "        y = np.concatenate((y, y_temp), axis=0).astype('float32')\n",
        "print(\"Shape, x: {}, y:{}\".format(x.shape, y.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category: fish, Label: 0, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: fork, Label: 1, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: hotdog, Label: 2, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: flamingo, Label: 3, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: airplane, Label: 4, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: alarmclock, Label: 5, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: baseballbat, Label: 6, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: bicycle, Label: 7, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: dolphin, Label: 8, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Category: elephant, Label: 9, X-Shape: (20000, 784) & Y-Shape: (20000,)\n",
            "Shape, x: (200000, 784), y:(200000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvWeDv5GXkDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Constructing the Fully Connected Neural Network with Softmax\n",
        "\n",
        "Use Tensorflow to train a fully connected neural network. "
      ]
    },
    {
      "metadata": {
        "id": "u0mqYDWKXfbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uIdCbSIJXq0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xr50IsSUXtWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [10000, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgmM_G23Xv6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
        "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \n",
        "    Tips:\n",
        "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
        "      In fact, the number of examples during test/train is different.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (approx. 2 lines)\n",
        "    X = tf.placeholder(tf.float32, name = 'X', shape=(n_x,None))\n",
        "    Y = tf.placeholder(tf.float32, name = 'Y', shape=(n_y,None))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxMAxyJ1XyeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [25, 12288]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [6, 12]\n",
        "                        b3 : [6, 1]\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
        "        \n",
        "    ### START CODE HERE ### (approx. 6 lines of code)\n",
        "    W1 = tf.get_variable(\"W1\", [25,784], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\", [12,25], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b2 = tf.get_variable(\"b2\", [12, 1], initializer= tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\", [10,12], initializer= tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b3 = tf.get_variable(\"b3\", [10, 1], initializer=tf.zeros_initializer())\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exlg7bX3X1ig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1,X), b1)                        # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1), b2)                      # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2), b3)                      # Z3 = np.dot(W3,Z2) + b3\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQokFdW5X4UL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(Z3, Y, lambd):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    # Include dropout\n",
        "    logits = tf.nn.dropout(logits, lambd)\n",
        "    \n",
        "    # compute cost\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVgtgnxSX7WL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          lambd = 0.001, num_epochs = 1500, minibatch_size = 100, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
        "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep consistent results\n",
        "    seed = 3                                          # to keep consistent results\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(Z3, Y, lambd)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], \n",
        "                                              feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1PReJQlYKLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running the Model\n",
        "\n",
        "We want to run the fully connected neural network."
      ]
    },
    {
      "metadata": {
        "id": "f0w4wX7sXVt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x, y = resahape_data(x, y)\n",
        "X_train, X_test, y_train, y_test = get_train_test(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ja67u4ZBYApX",
        "colab_type": "code",
        "outputId": "6925436e-13c4-455c-b992-c8eacd1b2366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 160000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "hbUgBssWYOBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "depth = len(categories)\n",
        "sess = tf.Session()\n",
        "y_train = sess.run(tf.one_hot(y_train, depth))\n",
        "y_test = sess.run(tf.one_hot(y_test, depth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6D1dbfRTLoDl",
        "colab_type": "code",
        "outputId": "12d89b20-3ed5-4ed9-e0d2-f91c70b123dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "y_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 160000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "01cG-lTXYQWP",
        "colab_type": "code",
        "outputId": "e7af67d7-42dd-4ba9-f34e-2caec7a2f78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "cell_type": "code",
      "source": [
        "parameters = model(X_train, y_train, X_test, y_test, learning_rate=0.001,  \n",
        "                   lambd=0.7, num_epochs =1600, minibatch_size=64)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.291805\n",
            "Cost after epoch 100: 0.860981\n",
            "Cost after epoch 200: 0.843858\n",
            "Cost after epoch 300: 0.833001\n",
            "Cost after epoch 400: 0.832235\n",
            "Cost after epoch 500: 0.828845\n",
            "Cost after epoch 600: 0.824759\n",
            "Cost after epoch 700: 0.826270\n",
            "Cost after epoch 800: 0.822886\n",
            "Cost after epoch 900: 0.822086\n",
            "Cost after epoch 1000: 0.819543\n",
            "Cost after epoch 1100: 0.817709\n",
            "Cost after epoch 1200: 0.815014\n",
            "Cost after epoch 1300: 0.816858\n",
            "Cost after epoch 1400: 0.818998\n",
            "Cost after epoch 1500: 0.817551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImIyCm8RERGTUXiLiIiYjMJbRETEZP4/Np4MN2QcF4IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f266fcf4b38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.866325\n",
            "Test Accuracy: 0.818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "elxWXwZ1YUJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}